{\rtf1\ansi\ansicpg950\cocoartf2822
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red193\green193\blue193;}
{\*\expandedcolortbl;;\cssrgb\c80000\c80000\c80000;}
\paperw11900\paperh16840\margl1440\margr1440\vieww20140\viewh7840\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs24 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Training model: QLoRA 2 Unfrozen Layer (Unfrozen Layers: 1)...\
`low_cpu_mem_usage` was None, now default to True since model is quantized.\
Trainable parameters:\
wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.5.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.5.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.5.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.5.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.5.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.5.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.6.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.6.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.6.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.6.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.6.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.6.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.7.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.7.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.7.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.7.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.7.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.7.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.8.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.8.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.8.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.8.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.8.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.8.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.9.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.9.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.9.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.9.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.9.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.9.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.10.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.10.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.10.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.10.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.10.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.10.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.11.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.11.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.11.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.11.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.11.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.11.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.12.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.12.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.12.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.12.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.12.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.12.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.13.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.13.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.13.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.13.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.13.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.13.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.14.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.14.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.14.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.14.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.14.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.14.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.15.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.15.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.15.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.15.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.15.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.15.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.16.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.16.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.16.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.16.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.16.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.16.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.17.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.17.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.17.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.17.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.17.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.17.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.18.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.18.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.18.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.18.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.18.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.18.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.19.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.19.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.19.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.19.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.19.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.19.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.20.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.20.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.20.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.20.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.20.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.20.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.21.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.21.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.21.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.21.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.21.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.21.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.22.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.22.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.22.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.22.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.22.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.22.attention.q_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.23.attention.k_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.23.attention.k_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.23.attention.v_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.23.attention.v_proj.lora_B.default.weight\
wav2vec2.base_model.model.encoder.layers.23.attention.q_proj.lora_A.default.weight\
wav2vec2.base_model.model.encoder.layers.23.attention.q_proj.lora_B.default.weight\
classifier.weight\
classifier.bias\
Total trainable parameters: 1186823\
Epoch 1 | Train Loss: 1.7101 | Val Loss: 1.4721 | Smoothed Val Loss: 1.4721 | LR: 6.00e-04 | Time: 149.05s\
Epoch 2 | Train Loss: 1.0884 | Val Loss: 0.7896 | Smoothed Val Loss: 1.1309 | LR: 6.00e-04 | Time: 109.02s\
Epoch 3 | Train Loss: 0.5819 | Val Loss: 0.5606 | Smoothed Val Loss: 0.6751 | LR: 3.00e-04 | Time: 106.97s\
Epoch 4 | Train Loss: 0.4142 | Val Loss: 0.5216 | Smoothed Val Loss: 0.5411 | LR: 3.00e-04 | Time: 107.01s\
Epoch 5 | Train Loss: 0.2361 | Val Loss: 0.5379 | Smoothed Val Loss: 0.5297 | LR: 1.50e-04 | Time: 106.94s\
Epoch 6 | Train Loss: 0.1485 | Val Loss: 0.6015 | Smoothed Val Loss: 0.5697 | LR: 1.50e-04 | Time: 107.53s\
Epoch 7 | Train Loss: 0.0649 | Val Loss: 0.6286 | Smoothed Val Loss: 0.6150 | LR: 7.50e-05 | Time: 106.73s\
Epoch 8 | Train Loss: 0.0353 | Val Loss: 0.7313 | Smoothed Val Loss: 0.6799 | LR: 7.50e-05 | Time: 106.93s\
Epoch 9 | Train Loss: 0.0208 | Val Loss: 0.7481 | Smoothed Val Loss: 0.7397 | LR: 3.75e-05 | Time: 106.87s\
Epoch 10 | Train Loss: 0.0140 | Val Loss: 0.7808 | Smoothed Val Loss: 0.7645 | LR: 3.75e-05 | Time: 107.96s\
Early stopping at epoch 10\
\
\uc0\u55356 \u57263  Evaluation Metrics (QLoRA 2 Unfrozen Layer):\
Accuracy:               0.8315\
Unweighted Avg Recall:  0.8382\
Weighted Recall:        0.8315\
Weighted F1 Score:      0.8305\
Cohen's Kappa:          0.8010\
\
Classification Report:\
              precision    recall  f1-score   support\
\
     disgust       0.83      0.90      0.86       186\
       happy       0.77      0.86      0.81       188\
         sad       0.79      0.67      0.72       186\
        fear       0.78      0.79      0.79       186\
     neutral       0.86      0.88      0.87       178\
       angry       0.93      0.88      0.90       186\
   surprised       0.96      0.90      0.93        59\
\
    accuracy                           0.83      1169\
   macro avg       0.85      0.84      0.84      1169\
weighted avg       0.83      0.83      0.83      1169\
\
Model saved to saved_models/w2v_qlora_t4_default.pth\
}